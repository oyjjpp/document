# MySql常见问题

## 索引

- [深入理解 Mysql 索引底层原理](https://zhuanlan.zhihu.com/p/73204847)
- [纸上得来终觉浅 绝知此事要躬行](https://www.cnblogs.com/MrYuChen-Blog/p/15672292.html)

```mysql
索引是对数据库表中一列或多列的值进行排序的一种结构。MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。
索引只是提高效率的一个因素，如果你的MySQL有大数据量的表，就需要花时间研究建立最优秀的索引或优化查询语句。

简单类比一下，数据库如同书籍，索引如同书籍目录，假如我们需要从书籍查找与 xx 相关的内容，我们可以直接从目录中查找，
定位到 xx 内容所在页面，如果目录中没有 xx 相关字符或者没有设置目录（索引），那只能逐字逐页阅读文本查找，效率可想而知。
```

### 为什么使用索引

最主要的原因是使用提高效率:

- 快速查找匹配where子句中的行
- 如果可以在多个索引中选择，mysql通常会使用找到最少行的索引
- 如果表具有多列索引，则优化器可以使用索引的任何最左前缀来查找行
- 当有表连接的时候，从其他表检索行数据
- 查找特定索引列的min和max的值
- 如果排序或者分组时可用索引的最左前缀完成的，则对表进行排序和分组
- 在某些情况下，可以优化查询以检索数据值而无需查找数据行

### 索引的优缺点

优点：

- 索引大大减小了服务器需要扫描的数据量，从而大大加快数据的检索速度，这也是创建索引的最主要的原因。
- 索引可以帮助服务器避免排序和创建临时表【B+树已经排序过的】
- 索引可以将随机IO变成顺序IO，减少IO次数
- 索引对于InnoDB（对索引支持行级锁）非常重要，因为它可以让查询锁更少的元组，提高了表访问并发性
- 关于InnoDB、索引和锁：InnoDB在二级索引上使用共享锁（读锁），但访问主键索引需要排他锁（写锁）
- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
- 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。
- 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。
- 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。

缺点：

- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加
- 索引需要占物理空间，除了数据表占用数据空间之外，每一个索引还要占用一定的物理空间，如果需要- 建立聚簇索引，那么需要占用的空间会更大
- 对表中的数据进行增、删、改的时候，索引也要动态的维护，这就降低了整数的维护速度
- 如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。
- 对于非常小的表，大部分情况下简单的全表扫描更高效；

### 创建索引准则

应该创建索引的列：

```mysql
1、在经常需要搜索的列上，可以加快搜索的速度；
2、在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构；
3、在经常用在连接（JOIN）的列上，这些列主要是一外键，可以加快连接的速度[少用]；
4、在经常需要根据范围（<，<=，=，>，>=，BETWEEN，IN）进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；
5、在经常需要排序（order by）的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间；
6、在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。
```

不该创建索引的列：

```mysql
1、对于那些在查询中很少使用或者参考的列不应该创建索引。若列很少使用到，因此有索引或者无索引，并不能提高查询速度。
相反由于增加了索引，反而降低了系统的维护速度和增大了空间需求。

2、对于那些只有很少数据值或者重复值多的列也不应该增加索引。【数据去重后的数据比趋于1,则索引效果越好】
这些列的取值很少，例如用户信息表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，
即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。

3、对于那些定义为text, image和bit数据类型的列不应该增加索引。这些列的数据量要么相当大，要么取值很少。

4、当该列修改性能要求远远高于检索性能时，不应该创建索引。（修改性能和检索性能是互相矛盾的）
```

### 索引的分类

```mysql
主键索引(唯一且非空)【数据库默认建立的索引是给唯一键建立的】
唯一索引(唯一可为空)
普通索引(普通字段的索引)
全文索引(一般是varchar,char,text类型建立的，但很少用)
组合索引(多个字的建立的索引)
```

### mysql索引结构？

MySQL索引是用于快速查找和访问数据库中数据的数据结构。在MySQL中，常用的索引结构包括B-Tree索引和哈希索引。

B-Tree索引
B-Tree（B树）是一种平衡树，它可以用于实现数据库索引。B-Tree索引是一种层级结构的索引，每个节点存储多个数据项和子节点的指针。

在MySQL中，B-Tree索引使用的是B+Tree，它的数据项存储在叶子节点中，非叶子节点仅存储索引键和子节点的指针。B+Tree索引的优点是可以支持范围查询、支持按照顺序遍历数据等操作，适用于数据量大、查询频繁的场景。

哈希索引
哈希索引是一种基于哈希表的索引结构，将数据存储在哈希表中，通过计算哈希值来查找数据。哈希索引适用于等值查询，但不支持范围查询和按照顺序遍历数据。

在MySQL中，哈希索引的实现是通过Memory存储引擎实现的，它可以用于缓存查询结果，但不适用于持久化存储。MySQL的InnoDB存储引擎不支持哈希索引。

除了B-Tree索引和哈希索引，MySQL还支持全文索引和空间索引等高级索引类型。全文索引用于对文本内容进行搜索，空间索引用于对空间数据（如地理位置信息）进行搜索。这些高级索引类型都是基于B-Tree索引实现的。


### 索引结构——二叉树

特性：  

- 所有非叶子结点至多拥有两个子节点（Left和Right）；
- 所有结点存储一个关键字；
- 非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树；

```mysql

二叉搜索树的搜索，从根结点开始，如果查询的关键字与结点关键字相等，则该结点为查询的结点，如果查询关键字比结点关键字小，则进入左子树，反之则进入右子树；如果左子树为空或者右子树为空，则返回查找不到响应的关键字；
如果二叉搜索树的所有叶子结点的左右子树的树木保持一个平衡即左右子树个数大致相等的话，其搜索则更接近与二分查找；但是它相比连续内存空的二分查找的优点是：改变二叉搜索树的结构（添加或者删除）不需要大段的移动数据，甚至通常都是常数开销；
```

![image](./image/20211208161626836.png)

```mysql
当一个二叉树经历多次删除操作后，就会出现树不平衡的状态，如上图所示。

右边也是一个搜索二叉树，只不过不在平衡了，他的搜索功能也变成了线性的，同样的关键字可能导致不同的树结构索引，所以，在使用搜索二叉树时，还要考虑尽可能让B树保持左图的结构，避免和右图类似，这也有事所谓的平衡问题了；

实际使用的二叉搜索树都是在原二叉搜索树的基础上加上平衡算法，即平衡二叉树；如何保持B树节点分布均匀的平衡算法就是平衡二叉树的关键所在，平衡算法是一种在二叉搜索树的插入和删除结点时的一种策略。即：在插入或删除的同时保持二叉搜索树的平衡。
```

### 索引结构——B Tree

```mysql
B-树,这里的B表示balance(平衡的意思),B-树是一种多路自平衡的搜索树（B树是一颗多路平衡查找树）它类似普通的平衡二叉树，不同的一点是B-树允许每个节点有更多的子节点；
```

B树是一种多路搜索树，一棵m阶的B树满足下列条件：

- 树中每个结点至少有M个孩子
- 根结点的子节点数为[2,M）
- 除根结点以外的非叶子结点的儿子数为[M/2, M]；
- 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字）
- 非叶子结点的关键字个数 = 指向子节点的指针个数-1；
- 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] < K[i+1]；
- 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树；
- 所有叶子结点位于同一层；

B树的特征:

- 关键字集合分布在整颗树中；
- 任何一个关键字出现且只出现在一个结点中；
- 搜索有可能在非叶子结点结束；
- 其搜索性能等价于在关键字全集内做一次二分查找；
- 自动层次控制；
- B树的搜索，从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的子结点；重复，直到所对应的子指针为空，或已经是叶子结点；

### 索引结构——B+Tree

```mysql
B+树是B-树的变体，也是一种多路搜索树，特性和B-类似，不同在于：

1、所有关键字存储在叶子节点出现,内部节点(非叶子节点并不存储真正的 data)
2、为所有叶子结点增加了一个链指针
```

```mysql
B+ 树的磁盘读写代价更低：B+ 树的数据都集中在叶子节点，分支节点 只负责指针（索引）；B 树的分支节点既有指针也有数据 。这将导致B+ 树的层高会小于B 树的层高，也就是说B+ 树平均的Io次数会小于B 树。

B+ 树的查询效率更加稳定：B+ 树的数据都存放在叶子节点，故任何关键字的查找必须走一条从根节点到叶子节点的路径。所有关键字的查询路径相同，每个数据查询效率相当。

B+树更便于遍历：由于B+树的数据都存储在叶子结点中，分支结点均为索引，遍历只需要扫描一遍叶子节点即可；B树因为其分支结点同样存储着数据，要找到具体的数据，需要进行一次中序遍历按序来搜索。

B+树更擅长范围查询：B+树叶子节点存放数据，数据是按顺序放置的双向链表。B树范围查询只能中序遍历。

B+ 树占用内存空间小：B+ 树索引节点没有数据，比较小。在内存有限的情况下，相比于B树索引可以加载更多B+ 树索引。
```

### B+树和B树有什么区别

B+树和B树都是一种平衡树，用于实现数据库索引，但它们有一些区别：

叶子节点：B树和B+树的叶子节点都存储了实际的数据，但是B+树的叶子节点只包含关键字和指向数据的指针，不存储实际的数据，而B树的叶子节点既包含关键字，也包含数据。

非叶子节点：B树和B+树的非叶子节点都包含了关键字和子节点的指针，但是B树的非叶子节点同时包含了关键字和子节点，而B+树的非叶子节点只包含了关键字，不包含子节点的指针。

查询操作：在B+树中，由于所有的数据都存储在叶子节点中，因此查找数据只需要遍历B+树的叶子节点。而在B树中，数据可能存储在任何一个节点中，因此查找数据需要遍历整棵树。

范围查询：由于B+树的叶子节点构成了一个有序链表，因此B+树支持范围查询和顺序遍历。而B树不支持这些操作，需要进行全量遍历。

磁盘IO：B+树的叶子节点构成了一个有序链表，可以减少磁盘IO次数，因此B+树适合于磁盘存储。而B树的非叶子节点和叶子节点都可能包含数据，因此B树的IO次数会更多，适合于内存存储。

总之，B+树和B树都是常用的平衡树数据结构，但是它们适用的场景不同，需要根据实际情况选择合适的数据结构。如果需要支持范围查询和顺序遍历，可以选择B+树，而如果数据全部存储在内存中，可以选择B树。

### 覆盖查询和回表查询

```mysql
在非主键索引上可以查询到所需要的字段，不需要回表再次查询就叫覆盖索引。

name字段是普通索引，从name列的B+树找到主键，再从主键的B+树找到最终的数据，这就是回表。(主键索引的叶子节点保存的是列的所有数据，但是普通所有的叶子结点保存的是对应的主键ID）

总结：通过普通索引B+树确定主键值，再到主键索引树，查找到具体数据，即为回表
```

### 聚簇索引和非聚簇索引

```mysql
InnoDB 里，索引B+ Tree的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引。

而索引B+ Tree的叶子节点存储了主键的值的是非主键索引，也被称之为非聚簇索引。
```

### mysql主键索引和非主键索引在搜索和检索过程中有什么区别吗？

```mysql
聚簇索引（clustered index）不是单独的一种索引类型，而是一种数据存储方式。这种存储方式是依靠B+树来实现的，根据表的主键构造一棵B+树且B+树叶子节点存放的都是表的行记录数据时，方可称该主键索引为聚簇索引。聚簇索引也可理解为将数据存储与索引放到了一块，找到索引也就找到了数据。

非聚簇索引：数据和索引是分开的，B+树叶子节点存放的不是数据表的行记录。
```

聚簇索引优点：

- 聚簇索引对于主键的排序查找和范围查找速度非常快
- 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快

聚簇索引缺点：

- 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键（主键列不要选没有意义的自增列，选经常查询的条件列才好，不然无法体现其主键索引性能）

- 更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。

- 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

### 哪些键可以设置唯一索引

```mysql
数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。
```

### 什么场景下联合索引会失效？

- 索引列上出现类型转换
- 存储引擎不能使用索引范围条件右边的列
- mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描
- is null,is not null也无法使用索引
- like以通配符开头（’%abc…’）mysql索引失效会变成全表扫描的操作。

### 最左匹配原则？问为什么有这个东西？

```mysql
组合索引中 先匹配左边，再继续向后匹配；比如user表中有name+age组成的联合索引，select * from user where name="纪先生" and age = 18 就符合最左匹配，可以用的索引。而select * from user where age = 18就不符合，用不到这个索引。

总结：组合索引顾头不顾未，想要使用索引，必须从组合索引的第一个字段开始。
```

### 数据库如何建索引

```mysql
主键索引
ALTER TABLE TableName ADD PRIMARY KEY(column_list); 

唯一索引
CREATE UNIQUE INDEX IndexName ON `TableName`(`字段名`(length));
# 或者
ALTER TABLE TableName ADD UNIQUE (column_list); 

普通索引
CREATE INDEX IndexName ON `TableName`(`字段名`(length));
# 或者
ALTER TABLE TableName ADD INDEX IndexName(`字段名`(length));
```

### sql索引优化问题

SQL 索引是一种常用的优化数据库查询性能的方法，可以大大提高查询的效率。以下是 SQL 索引优化的一些常见问题：

什么是索引？
索引是数据库中用于加速数据访问的一种数据结构。它们是通过一个数据结构来存储表中的数据，从而提供快速的查询和排序。当创建索引时，它会在数据库中创建一个表格，包含列名和索引键的值。这样，查询时可以在索引表格中查找相应的记录，而不需要扫描整个数据表。

索引如何提高查询性能？
索引可以大大提高数据库的查询性能，因为它可以使数据库在查找数据时不需要扫描整个数据表，而是直接通过索引表格来定位相应的数据行。这可以大大减少数据库的 I/O 操作，从而提高查询速度。

如何选择索引列？
在选择索引列时，应该选择经常被用于查询、过滤、排序和分组的列。同时，也要考虑到索引的选择性。索引的选择性指的是索引列中不同值的数量与总行数之比。选择性越高，索引的效果就越好。

如何优化索引？
在优化索引时，可以采用以下几种方法：

删除不必要的索引，只保留那些经常被用到的索引；
尽量使用覆盖索引，避免使用全表扫描；
对复合索引的列进行优化，优先考虑选择性高的列作为索引前缀；
使用索引提示强制使用特定的索引；
定期对数据库进行性能测试和监控，及时发现问题并进行优化。


索引可能带来的问题？
尽管索引可以大大提高数据库的查询性能，但是也可能带来以下问题：

索引需要占用存储空间，可能会占用较大的存储空间；
当数据库表中的数据频繁更新时，索引也需要随之更新，会增加数据库的写入操作的开销；
过多的索引可能会影响数据库的性能，因为它们需要占用额外的存储空间，并且在查询时需要额外的处理时间。
因此，在使用索引时，需要根据具体情况进行权衡和优化。

### MySQL优化（索引、分表分库）

### mysql索引，mongodb和mysql索引的区别，给了条sql语句问索引怎么构建

## 性能

[MySQL Explain详解](https://zhuanlan.zhihu.com/p/409658674)

### explain字段含义

### sql查询性能瓶颈处理方式

SQL查询性能瓶颈的处理方式通常包括以下几个方面：

1、优化SQL语句：优化SQL语句可以通过修改SQL查询语句，减少查询中不必要的计算和数据扫描，提高查询效率。例如，可以使用索引、合理地使用JOIN语句、减少子查询和重构查询语句等方式进行优化。

2、增加或修改索引：索引是数据库中提高查询效率的重要手段。可以根据查询需求，增加或修改相应的索引，以减少数据扫描的次数，提高查询效率。

3、增加缓存：缓存可以将常用的数据存储在内存中，减少数据库的访问次数，提高查询效率。可以使用缓存技术，如Memcached、Redis等，将查询结果缓存到内存中。

4、数据库分区：将数据按照某种方式进行分区，可以将大表分解为多个小表，减少数据扫描的时间，提高查询效率。

5、优化硬件设备：硬件设备的性能对SQL查询效率也有很大的影响。可以增加内存、CPU等硬件设备的配置，提高数据库服务器的性能。

6、优化数据库架构：数据库架构也会对SQL查询效率产生影响。可以通过对数据库架构进行优化，如分库分表、读写分离、负载均衡等，提高查询效率。

总之，SQL查询性能瓶颈的处理方式需要根据具体情况而定。可以通过多方面的优化来提高查询效率，以满足业务需求。

### 一条update语录执行流程
1、语法解析和语义检查：数据库系统首先对 UPDATE 语句进行语法解析和语义检查，以确保语句符合 SQL 标准和数据库的规范要求。

2、查询优化和执行计划生成：在查询优化阶段，数据库系统会根据查询条件、表结构、索引等因素，生成一个最优的执行计划，以尽量减少查询时间和系统资源的消耗。

3、锁定数据行：在执行 UPDATE 语句之前，数据库系统需要先锁定需要更新的数据行，以避免其他用户对同一行数据进行修改，造成数据不一致的问题。

4、执行数据更新：一旦数据行被锁定，数据库系统会执行具体的数据更新操作，包括对目标表中的数据行进行修改、删除和插入操作等。

5、提交事务：如果 UPDATE 语句是在事务中执行的，那么在更新操作完成后，需要将事务提交给数据库系统，以保证数据的一致性和可靠性。

6、释放锁定：一旦 UPDATE 语句执行完成并且事务提交成功，数据库系统会释放已经锁定的数据行，以允许其他用户对这些数据行进行修改和访问。

需要注意的是，在 UPDATE 语句的执行过程中，数据库系统需要进行大量的 I/O 操作和计算操作，因此可能会对系统资源造成较大的负担。为了优化 UPDATE 语句的执行效率，需要采取一些措施，如创建合适的索引、优化查询语句等。

### 一条sql的查询过程

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a1a573fad98d453ba60f9babdade0b8d~tplv-k3u1fbpfcp-watermark.image)

### sql索引优化方式，explain字段含义

SQL索引优化的方式包括以下几个方面：

1、建立合适的索引：通过创建合适的索引可以提高查询效率。通常，需要在经常使用的WHERE和JOIN子句的列上建立索引，以减少数据的扫描次数。

2、删除不必要的索引：不必要的索引会降低数据库的写入性能，因此需要定期检查数据库中的索引，并删除不必要的索引。

3、优化查询语句：通过优化查询语句可以减少数据的扫描次数。例如，避免使用SELECT *，使用EXISTS代替IN子查询，合理使用JOIN语句等。

4、避免全表扫描：全表扫描会消耗大量的系统资源，降低数据库的性能。可以通过建立合适的索引、优化查询语句等方式避免全表扫描。

5、分区表：将表按照某种规则进行分区，可以提高查询效率，减少数据扫描的次数。

EXPLAIN是MySQL中用于查询语句优化的工具，通过使用EXPLAIN可以查看查询执行计划，并分析查询性能。在查询语句前加上EXPLAIN，即可查看查询的执行计划。

EXPLAIN查询结果中的字段含义如下：

- id：查询的序列号，按照查询的执行顺序递增。
- select_type：查询类型，包括SIMPLE、PRIMARY、SUBQUERY等。
- table：查询的表名。
- partitions：使用的分区，如果有的话。
- type：访问类型，包括ALL、index、range、ref、eq_ref、const、system、NULL等。
- possible_keys：可以使用的索引。
- key：实际使用的索引。
- key_len：使用的索引的长度。
- ref：连接的列。
- rows：扫描的行数。
- filtered：过滤的行数。
- Extra：附加信息，包括Using index、Using where等。
通过分析EXPLAIN查询结果，可以找到查询语句的瓶颈，并进行相应的优化。

### B+树细节优势，和哈希索引的区别，是为了解决什么问题

B+树是一种常用的数据结构，用于实现关系型数据库中的索引。B+树相较于其他索引结构（如B树、哈希索引等）具有以下优势：

- B+树支持范围查询：B+树中的每个节点都是一个有序的链表，可以通过遍历链表实现范围查询。这种特性在数据库中非常重要，因为范围查询是一种常见的查询方式。

- B+树支持顺序访问：由于B+树中所有数据都存在叶子节点中，因此可以通过顺序遍历叶子节点来实现对数据的顺序访问，从而提高查询性能。

- B+树支持高效的插入和删除：B+树采用了分裂和合并节点的方式来动态维护树的平衡，因此插入和删除操作的时间复杂度为O(log n)，比其他数据结构更加高效。

相比之下，哈希索引的主要优点是查询速度非常快，因为哈希索引中的数据是根据哈希函数直接存储在哈希表中的，可以通过O(1)的时间复杂度进行查询。但哈希索引的缺点是不支持范围查询和顺序访问，因此在这些场景下会表现得比B+树更加低效。

B+树的主要应用场景是在数据库中实现索引，用于提高查询性能。它可以在支持范围查询、顺序访问和高效插入/删除的同时，保持树的平衡，避免出现数据倾斜和树的深度过大等问题。因此，B+树可以在关系型数据库中高效地支持各种查询操作。

### 什么操作会影响联表查询效率

### 分析sql性能好坏如何分析？

### 一条sql语句比较慢用什么方式去优化？

### sql慢查询

### mysql索引慢分析：线上开启slowlog，提取慢查询，然后仔细分析explain中tye字段以及extra字段，发生的具体场景及mysql是怎么做的

### 关心过业务系统里面的sql耗时吗?统计过慢查询吗?对慢查询都怎么优化过?

```mysql
慢查询的优化首先要搞明白慢的原因是什么?
是查询条件没有命中索引?
是load了不需要的数据列?还是数据量太大?
1、首先分析语句,看看是否load了额外的数据,可能是查询了多余的行并且抛弃掉了,可能是加载了许多结果中并不需要的列,对语句进行分析以及重写.
2、分析语句的执行计划,然后获得其使用索引的情况,之后修改语句或者修改索引,使得语句可以尽可能的命中索引.
3、如果对语句的优化已经无法进行,可以考虑表中的数据量是否太大,如果是的话可以进行横向或者纵向的分表
```

## 事务

[mysql 事务](https://www.cnblogs.com/MrYuChen-Blog/p/15684602.html)

```mysql
数据中的事务是指，对数据库执行一批操作，该操作是一个原子操作，是一个最小执行单位，可以有多个sql语句组成，在整个操作中，所有sql语句必须成功，有一个sql执行失败，则整个操作都失败，数据回滚。这样的操作就是一组事务。
```

### 事物四个特性？四种隔离级别？分别解决了什么问题？

事务的四个特性是：

- 原子性（Atomicity）：一个事务要么全部完成，要么全部不完成，不可能停留在中间状态。
- 一致性（Consistency）：事务执行前后，数据库从一个一致性状态转换到另一个一致性状态。
- 隔离性（Isolation）：一个事务的执行不能被其他事务干扰，即每个事务都应该感觉不到其他事务的存在。
- 持久性（Durability）：事务完成后，对数据库的改变应该是永久性的。

事务的四个隔离级别是：

- 读未提交（Read Uncommitted）：一个事务可以读取另一个事务尚未提交的数据，可能会出现脏读、不可重复读和幻读的问题。
- 读已提交（Read Committed）：一个事务只能读取另一个事务已经提交的数据，可以避免脏读的问题，但是不可重复读和幻读的问题仍然可能出现。
- 可重复读（Repeatable Read）：一个事务在执行过程中多次读取同一个数据时，能够保证每次读取到的数据都是一致的，可以避免脏读和不可重复读的问题，但是仍可能出现幻读的问题。
- 序列化（Serializable）：最高级别的隔离级别，可以避免所有并发问题，但是性能较差，一般不建议使用。该级别保证所有事务串行执行，不会出现脏读、不可重复读和幻读的问题。

### 事务分类

```mysql
mysql中事务默认是隐式事务，执行insert、update、delete操作的时候，数据库自动开启事务、提交或回滚事务。

是否开启隐式事务是由变量autocommit控制的。

所以事务分为隐式事务和显式事务。
```

### 事务的隔离性和隔离级别

```mysql
#mysql5.7及之后版本
show variables like 'transaction_isolation';或者select @@transaction_isolation;

#mysql5.7之前版本
show variables like 'tx_isolation';或者select @@tx_isolation;

#注意mysql5.7之后才是transaction_isolation,之前都是tx_isolation,但是mysql8.0.3之后tx_isolation就被去掉了
```

#### 读未提交：read uncommitted

- 事物A和事物B，事物A未提交的数据，事物B可以读取到;
- 这里读取到的数据叫做“脏数据”;
- 这种隔离级别最低，这种级别一般是在理论上存在，数据库隔离级别一般都高于该级别。

#### 读已提交：read committed

- 事物A和事物B，事物A提交的数据，事物B才能读取到，这种隔离级别高于读未提交，换句话说，对方事物提交之后的数据，我当前事物才能读取到;
- Oracle默认隔离级别
- 这种级别可以避免“脏数据”
- 【会产生的问题】：不可重复读、幻读

#### 可重复读：repeatable read

- 事务A和事务B，事务A提交之后的数据，事务B读取不到
- 事务B是可重复读取数据
- 这种隔离级别高于读已提交
- 换句话说，对方提交之后的数据，我还是读取不到
- 这种隔离级别可以避免“不可重复读取”，达到可重复读取
- 比如1点和2点读到数据是同一个
- MySQL默认级别
- 【会产生的问题】：幻读

#### 串行化：serializable

- 事务A和事务B，事务A在操作数据库时，事务B只能排队等待
- 这种隔离级别很少使用，吞吐量太低，用户体验差
- 这种级别可以避免“幻像读”，每一次读取的都是数据库中真实存在数据，事务A与事务B串行，而不并发

```mysql
隔离级别从小到大，安全性越来越高，但是效率越来越低。但是一般情况下不会修改数据库默认的隔离级别，只有在极特殊情况下才会做出修改已解决一些特殊问题。
```

### 脏读、幻读、不可重复读

#### 脏读

- 读未提交产生脏读问题
- 脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。【简单说，事务A读取了事务B为提交的数据，可能使得最后提交的数据不正确】

| 时间顺序 | 转账事务 | 取款事务 |
| :-- | :-- | :-- |
| 1 | | start transaction |
| 2 | start transaction | |
| 3 | | 查询账户余额为2000元 |
| 4 | | 取款1000元，余额被更改为1000元（未提交）|
| 5 | 查询账户余额为1000元（产生脏数据）| |
| 6 | | 取款操作发生未知错误，事务回滚，余额变更为2000元 |
| 7 | 转入2000元，余额被更改为3000元（脏读1000+2000）| |
| 8 | 提交事务 | |
| 备注 | 按照正常逻辑此时账户应该为4000元 |

#### 不可重复读

- 在同一事务中，多次读取同一数据返回的结果有所不同，换句话说，后续读取可以读到另一事务已提交的更新数据。

| 时间顺序 | 事务A  | 事务B |
| :-- | :-- | :-- |
| 1 | start transaction | |
| 2 | select年龄为20岁 | |
| 3 | | start transaction |
| 4 | 其他操作 | |
| 5 | | update年龄30岁 |
| 6 | | |
| 7 | select 年龄30岁 | commit |
| 备注 | 按照正常逻辑，事务A的前后两次读取到的数据应该一致 | |

```mysql
有一个比较长的事务正在执行，这个时候，另外一个事务读取了相同的数据，进行修改，并且提交持久化到数据库，这个时候比较长的事务读取到的数据是新的数据，和第一次读取的不一样。
```

#### 幻读

- 幻读在可重复读的模式下才会出现
- 一个事务操作（DML）数据表中所有的记录，另一个事务添加了一条数据，则第一个事务查询不到自己的修改；

| 时间顺序 | 事务A  | 事务B |
| :-- | :-- | :-- |
| 1 | start transaction | |
| 2 | | start transaction |
| 3 | 其他操作 | |
| 4 | | insert 100条数据 |
| 5 | | commit |
| 6 | select count(*) 200条 | |
| 备注 | 按照正常逻辑，事务A前后两次读取到的数据总量应该一致 | |

#### 不可重复读和幻读区别

```mysql
问题1：不可重复读是读取了其他事务更改的数据，针对update操作

解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许其他事务更改刚才的数据。
```

```mysql
问题2：幻读是读取了其他事务新增的数据，针对insert与delete操作

解决：使用表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，这个时候才允许其他事务新增数据。
```

```mysql
幻读和不可重复读都是指的一个事务范围内的操作受到其他事务的影响了。只不过幻读是重点在插入和删除，不可重复读重点在修改
```

### 事务实现原理

```mysql
事务的四大特性，一致性，原子性，隔离性以及持久性，这些特性无非不是在保证数据库的可靠性以及并发处理。
```

可靠性：

```mysql
数据库要保证当insert或update操作时抛异常或者数据库crash的时候需要保障数据的操作前后的一致，想要做到这个，
我需要知道我修改之前和修改之后的状态，所以就有了undo log和redo log。
```

并发处理：

```mysql
也就是说当多个并发请求过来，并且其中有一个请求是对数据修改操作的时候会有影响，为了避免读到脏数据，所以需要对事务之间的读写进行隔离，至于隔离到啥程度得看业务系统的场景了，实现这个就得用MySQL 的隔离级别。
```

实现事务功能的三个技术:

- 日志文件(redo log 和 undo log)
- 锁技术
- MVCC

#### redo log【重做日志】

redo log是用来恢复数据的，用于保障，已提交事务的持久化特性（记录了已经提交的操作）

```mysql
redo log叫做重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。
当事务提交之后会把所有修改信息都会存到该日志中。
```

```mysql
mysql 为了提升性能不会把每次的修改都实时同步到磁盘，而是会先存到Boffer Pool(缓冲池)里头，把这个当作缓存来用。然后使用后台线程去做缓冲池和磁盘之间的同步。

那么问题来了，如果还没来的同步的时候宕机或断电了怎么办？这样会导致丢部分已提交事务的修改信息！

所以引入了redo log来记录已成功提交事务的修改信息，并且会把redo log持久化到磁盘，系统重启之后在读取redo log恢复最新数据。
```

#### undo log【回滚日志】

undo log 记录事务修改之前版本的数据信息，因此假如由于系统错误或者rollback操作而回滚的话可以根据undo log的信息来进行回滚到没被修改前的状态。

```mysql
undo log 叫做回滚日志，用于记录数据被修改前的信息。正好跟前面所说的重做日志所记录的相反，重做日志记录数据被修改后的信息。undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚。

每次写入数据或者修改数据之前都会把修改前的信息记录到 undo log

```

- 每条数据变更(insert/update/delete)操作都伴随一条undo log的生成,并且回滚日志必须先于数据持久化到磁盘上
- 所谓的回滚就是根据回滚日志做逆向操作，比如delete的逆向操作为insert，insert的逆向操作为delete，update的逆向为update等

```mysql
为了做到同时成功或者失败，当系统发生错误或者执行rollback操作时需要根据undo log 进行回滚

回滚操作就是要还原到原来的状态，undo log记录了数据被修改前的信息以及新增和被删除的数据信息，根据undo log生成回滚语句，比如：

1、如果在回滚日志里有新增数据记录，则生成删除该条的语句；
2、如果在回滚日志里有删除数据记录，则生成生成该条的语句；
3、如果在回滚日志里有修改数据记录，则生成修改到原先数据的语句。
```

#### mysql锁

通过读写锁，可以做到读读可以并行，但是不能做到写读，写写并行

```mysql
当有大量请求读数据表时，仅仅是读并不需要使用锁，但是当有多个请求修改或者是新增数据时，为了防止数据的正确性，就需要使用锁控制并发。
```

```mysql
共享锁(shared lock),又叫做"读锁"
读锁是可以共享的，或者说多个读请求可以共享一把锁读数据，不会造成阻塞。

排他锁(exclusive lock),又叫做"写锁"
写锁会排斥其他所有获取锁的请求，一直阻塞，直到写入完成释放锁。
```

#### MVCC多版本并发控制

[MVCC基本原理](https://www.cnblogs.com/chinesern/p/7592537.html)

```mysql
MVCC (MultiVersion Concurrency Control) 叫做多版本并发控制。一般情况下，事务性储存引擎不是只使用表锁，行加锁的处理数据，而是结合了MVCC机制，以处理更多的并发问题。Mvcc处理高并发能力最强，但系统开销比较大（较表锁、行级锁），这是最求高并发付出的代价。
```

### 这个隔离级别是如何实现的？

### 如果实现分布式事务？

## 分库分表

- [MySQL 分库分表方案，总结的非常好！](https://mp.weixin.qq.com/s?__biz=MzI0MDQ4MTM5NQ==&mid=2247485778&idx=1&sn=4297eaea0092de38fc2624a605d8afbe&chksm=e91b6c4ede6ce558ec7fc2060ed9f0a53887324d07db39e5dbad351ab041bb1f25a06ab6a217#rd)
- [不用找了，大厂在用的分库分表方案，都在这里！](https://mp.weixin.qq.com/s?__biz=MzU0OTk3ODQ3Ng==&mid=2247486543&idx=1&sn=81020eac4b50d304714bd0771eda0ec3&chksm=fba6e44cccd16d5ad79ff53b927d08a369dcac2581352182f5f8308c05d22aeedcea7f7b489e)
- [一口气说出9种分布式ID生成方式，阿里面试官都懵了](https://zhuanlan.zhihu.com/p/152179727)

### 数据库瓶颈

```mysql
不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承
载活跃连接数的阈值。

在业务Service来看就是，可用数据库连接少甚至无连接可用。接下来就可以想象了吧（并发量、吞吐量、崩溃）。
```

**IO瓶颈：**

```mysql
第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度 -> 分库和垂直分表。

第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 -> 分库。
```

**CPU瓶颈：**

```mysql
第一种：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运
算的操作 -> SQL优化，建立合适的索引，在业务Service层进行业务计算。

第二种：单表数据量太大，查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈 -> 水平分表。
```

### 分库分表查询方式，数据库分库分表，什么时候分库什么时候分表

```mysql
一般就是垂直切分和水平切分，这是一种结果集描述的切分方式，是物理空间上的切分。 我们从面临
的问题，开始解决，阐述： 首先是用户请求量太大，我们就堆机器搞定（这不是本文重点）。

然后是单个库太大，这时我们要看是因为表多而导致数据多，还是因为单张表里面的数据多。 如果是
因为表多而数据多，使用垂直切分，根据业务切分成不同的库。

如果是因为单张表的数据量太大，这时要用水平切分，即把表的数据按某种规则切分成多张表，甚至
多个库上的多张表。 

分库分表的顺序应该是先垂直分，后水平分。 因为垂直分更简单，更符合我们处理现实世界问题的方式。
```

### 垂直拆分

**垂直分表：**

![垂直分库](./image/202210310857.png)

```mysql
也就是“大表拆小表”，基于列字段进行的；一般是表中的字段较多，将不常用的，数据较大，长度较长
（比如text类型字段）的拆分到“扩展表“；一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。

1.概念：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。

2.结果：
每个表的结构都不一样；
每个表的数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据；
所有表的并集是全量数据；

3.场景：
系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，
单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。

4.分析：
可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的
数据）放在一起作为主表，非热点数据放在一起作为扩展表。

这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。

但记住，千万别用join，因为join不仅会增加CPU负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。

关联数据，应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。
```

**垂直分库：**

![垂直分库](./image/202210310854.png)

```mysql
1.概念：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。

2.结果：
每个库的结构都不一样；
每个库的数据也不一样，没有交集；
所有库的并集是全量数据；

3.场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。

4.分析：到这一步，基本上就可以服务化了。

例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。
再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。

垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，
订单Order一个库。 切分后要放在多个服务器上，而不是一个服务器上。为什么？ 我们想象一下，
一个购物网站对外提供服务，会有用户，商品，订单等的CRUD。没拆分之前， 全部都是落到单一的
库上的，这会让数据库的单库处理能力成为瓶颈。按垂直分库后，如果还是放在一个数据库服务器上，
 随着用户量增大，这会让单个数据库的处理能力成为瓶颈，还有单个服务器的磁盘空间，内存，tps
 等非常吃紧。 所以我们要拆分到多个服务器上，这样上面的问题都解决了，以后也不会面对单机资源问题。

数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理，
维护，监控，扩展等。 数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对
于Web和应用服务器来讲，是比较难实现“横向扩展”的。 数据库的连接资源比较宝贵且单机处理能力
也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。
```

### 水平拆分

**水平分表：**
![水平分表](./image/20211208161626836.png)

```mysql
针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面
去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。

1.概念：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。

2.结果：

每个表的结构都一样
每个表的数据都不一样，没有交集;
所有表的并集是全量数据;

3.场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。

4.分析：表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。
```

**水平分库：**
![水平分库](./image/640.png)

```mysql
将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。
水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

1、概念：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。

2、结果：
每个库的结构都一样;
每个库的数据都不一样，没有交集;
所有库的并集是全量数据;

3、场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。

4、分析：库多了，io和cpu的压力自然可以成倍缓解。
```

**水平分库分表切分规则：**

```mysql
1、RANGE
从0到10000一个表，10001到20000一个表；

2、HASH取模
一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库
事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。

3、地理区域
比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。

4、时间
按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，
这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。
```

### 分库分表后面临的问题

**事务支持：**

```mysql
分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出
高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。
```

**跨库join：**

```mysql
分库分表后表之间的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不
同的表， 结果原本一次查询能够完成的业务，可能需要多次查询才能完成。 

粗略的解决方法： 
全局表：基础数据，所有库都拷贝一份。 
字段冗余：这样有些字段就不用join去查询了。 
系统层组装：分别查询出所有，然后组装起来，较复杂。
```

### 分库分表方案产品

```mysql
目前市面上的分库分表中间件相对较多，
其中基于代理方式的有MySQL Proxy和Amoeba， 
基于Hibernate框架的是Hibernate Shards，
基于jdbc的有当当sharding-jdbc， 
基于mybatis的类似maven插件式的有蘑菇街的蘑菇街TSharding， 
通过重写spring的ibatis template类的Cobar Client。
```

![image](./image/640.jpg)

### 分库之后唯一性如何保证

### 分库分表分区有哪些差别？

### 分表遇到联表查询怎么分页？

### 分库分表常用模式

### 一开始一个项目数据比较多，后来需要分库分表，有什么思路在不停服务的情况下做到平滑切换？

## 设计

### 设计用户详情的表，如何生成主键

### 对mysql的设计掌握如何？

### 数据库用过哪些？

## 存储引擎

### mysql默认的存储引擎

### mysql的存储引擎了解哪些？区别是啥？

```mysql
InnoDB、MyISAM、memory、archive
mysql存储引擎是可插拔的，核心基础代码是与存储引擎分离的

1、InnoDB  
优点  
a、灾难恢复性好  
b、支持全部4种级别的事务  
c、使用行级锁  
d、对于innodb引擎中的表，数据的物理组织形式是簇表（数据按主键来组织，主键索引和数据是在一起的） 
e、实现了缓存管理  

2、MyISAM  
特点  
a、可以配合锁，实现操作系统下的复制备份，迁移  
b、使用表级锁，并发性能差  
c、支持全文检索  
d、灾难恢复性不佳  
e、不支持事务  
f、仅缓存索引  

3、memory  
提供内存表，也不支持事务，外键；使用内存表可以显著提供访问数据的速度，可以应用于频繁访问的  

4、archive  
被设计用来存储企业中的大量流水数据的存储引擎，使用zlib无损数据压缩，适合做日志记录，用户行为分析

```

## Mysql相关锁

- [MySQL锁总结](https://zhuanlan.zhihu.com/p/29150809)  
- [全面了解mysql锁机制（InnoDB）与问题排查](https://juejin.cn/post/6844903668571963406)  
- [Mysql 共享锁(lock in share mode)，排他锁(for update)](https://segmentfault.com/a/1190000015210634)

```mysql
锁是计算机协调多个进程或线程并发访问某一资源的机制。
锁保证数据并发访问的一致性、有效性；锁冲突也是影响数据库并发访问性能的一个重要因素。
锁是Mysql在服务器层和存储引擎层的的并发控制。

加锁是消耗资源的，锁的各种操作，包括获得锁、检测锁是否是否已解除、释放锁等。
```

### 锁粒度

```mysql
MySQL不同的存储引擎支持不同的锁机制，所有的存储引擎都以自己的方式显现了锁机制，服务器层完全不了解存储引擎中的锁实现；
默认情况下，表锁和行锁都是自动获得的，不需要额外的命令；
但是在有的情况下，用户需要明确地进行锁表或者进行事务的控制，以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。
```

- MyISAM 和 MEMORY 存储引擎采用的是表级锁（table-level locking）
- BDB 存储引擎采用的是页面锁（page-level locking），但也支持表级锁
- InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。

### 不同粒度锁的比较

```mysql
表级锁：
开销小，加锁快，不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；
这些存储引擎通过总是一次性同时获取所有需要的锁以及总是按相同的顺序获取表锁来避免死锁；
表级锁更适合于以查询为主，并发用户少，只有少量按索引条件更新数据的应用，如Web 应用。

行级锁：
开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高；
最大程度的支持并发，同时也带来了最大的锁开销。
在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了在InnoDB中发生死锁是可能的。
行级锁只在存储引擎层实现，而Mysql服务器层没有实现。 
行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。

页面锁：
开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。
```

### MyISAM表级锁模式

- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

```mysql
MyISAM表的读操作与写操作之间，以及写操作之间是串行的。
当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。 
其他线程的读、写操作都会等待，直到锁被释放为止。

默认情况下，写锁比读锁具有更高的优先级，当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。
```

**可以设置改变读锁和写锁的优先级：**

- 指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。
- 执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。
- 指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。
- 给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。

### MyISAM加表锁方法

```mysql
MyISAM 在执行查询语句（SELECT）前，会自动给涉及的表加读锁；
在执行更新操作（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁；
这个过程并不需要用户干预，因此用户一般不需要直接用 LOCK TABLE命令给MyISAM表显式加锁。


在自动加锁的情况下，MyISAM总是一次获得SQL语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。

MyISAM存储引擎支持并发插入，以减少给定表的读和写操作之间的争用：

如果MyISAM表在数据文件中间没有空闲块，则行始终插入数据文件的末尾。在这种情况下，你可以自
由混合并发使用MyISAM表的INSERT和SELECT语句而不需要加锁——你可以在其他线程进行读操作的时候，同时将行插入到MyISAM表中。

如果文件中间有空闲快，则并发插入会被禁用，但是当所有空闲块都填充有新数据时，它又会自动重
新启用；要控制此行为，可以使用MySQL的concurrent_insert系统变量。

如果你使用LOCK TABLES显式获取表锁，则可以请求READ LOCAL锁而不是READ锁，以便在锁定表时，其他会话可以使用并发插入。
```

- 当concurrent_insert设置为0时，不允许并发插入。
- 当concurrent_insert设置为1时，如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个线程读表的同时，另一个线程从表尾插入记录。这也是MySQL的默认设置。
- 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录。

### 查询表级锁争用情况

```mysql
通过检查 table_locks_waited 和 table_locks_immediate 状态变量来分析系统上的表锁的争夺，
如果 Table_locks_waited 的值比较高，则说明存在着较严重的表级锁争用情况：

mysql> SHOW STATUS LIKE 'Table%';
+----------------------------+----------+
| Variable_name              | Value    |
+----------------------------+----------+
| Table_locks_immediate      | 55320843 |
| Table_locks_waited         | 0        |
+----------------------------+----------+
```

### InnoDB锁模式

InnoDB 实现了以下两种类型的行锁：

- 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

锁模式的兼容情况：
![image](./image/lock.png)

### InnoDB加锁方法

**隐式锁定：**

- 意向锁是InnoDB自动加的，不需用户干预。
- 对于UPDATE、 DELETE 和 INSERT 语句， InnoDB会自动给涉及数据集加排他锁（X)；
- 对于普通 SELECT 语句，InnoDB 不会加任何锁；

```mysql
InnoDB在事务执行过程中，使用两阶段锁协议：
随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自动加锁；
锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在同一时刻被释放。
```

**显式锁定 ：**

- 共享锁（S）：SELECT *FROM table_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。
- 排他锁（X)：SELECT* FROM table_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁

```mysql
select ... lock in share mode //共享锁 
select ... for update //排他锁 
```

**select for update：**

```mysql
在执行这个 select 查询语句的时候，会将对应的索引访问条目进行上排他锁（X 锁），也就是说这个语句对应的锁就相当于update带来的效果。

使用场景：为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。
```

**lock in share mode ：**

```mysql
lock in share mode 子句的作用就是将查找到的数据加上一个 share 锁，这个就是表示其他的事务只能对这些数据进行简单的select 操作，并不能够进行 DML 操作。

使用场景：为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据 使用了 in share mode 的方式上了 S 锁。
```

**for update 和 lock in share mode 的区别：**

```mysql
前一个上的是排他锁（X 锁），一旦一个事务获取了X锁，其他的事务是没法在这些数据上执行 for update ；
后一个是共享锁，多个事务可以同时的对相同数据执行 lock in share mode。
```

**性能影响：**

```mysql
for update 语句，相当于一个 update 语句。在业务繁忙的情况下，如果事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。

lock in share mode 语句是一个给查找的数据上一个共享锁（S 锁）的功能，它允许其他的事务也对该数据上S锁，但是不能够允许对该数据进行修改。如果不及时的commit 或者rollback 也可能会造成大量的事务等待。
```

### InnoDB 行锁实现方式

- 1、InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！

- 2、不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。

- 3、只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引。

- 4、由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点。

### InnoDB的间隙锁

```mysql
当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。

在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。
```

**InnoDB使用间隙锁的目的：**

- 防止幻读，以满足相关隔离级别的要求；
- 满足恢复和复制的需要；

```mysql
MySQL 通过 BINLOG 录入执行成功的 INSERT、UPDATE、DELETE 等更新数据的 SQL 语句，
并由此实现 MySQL 数据库的恢复和主从复制。

MySQL 的恢复机制（复制其实就是在 Slave Mysql 不断做基于 BINLOG 的恢复）有以下特点：
1、MySQL的恢复是 SQL 语句级的，也就是重新执行 BINLOG 中的 SQL 语句。
2、MySQL 的 Binlog 是按照事务提交的先后顺序记录的， 恢复也是按这个顺序进行的。

MySQL 的恢复机制要求：
在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。
```

### 获取 InnoDB 行锁争用情况

```mysql
mysql> show status like 'innodb_row_lock%'; 
+-------------------------------+-------+ 
| Variable_name | Value | 
+-------------------------------+-------+ 
| InnoDB_row_lock_current_waits | 0 | 
| InnoDB_row_lock_time | 0 | 
| InnoDB_row_lock_time_avg | 0 | 
| InnoDB_row_lock_time_max | 0 | 
| InnoDB_row_lock_waits | 0 | 
```

### LOCK TABLES 和 UNLOCK TABLES

```mysql
Mysql也支持lock tables和unlock tables，这都是在服务器层（MySQL Server层）实现的，
和存储引擎无关，它们有自己的用途，并不能替代事务处理。 （除了禁用了autocommint后可以使用，其他情况不建议使用）：
```

- LOCK TABLES 可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止。
- UNLOCK TABLES 可以释放当前线程获得的任何锁定。当前线程执行另一个 LOCK TABLES 时，
或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁

### 死锁（Deadlock Free）

**死锁产生：**

- 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。
- 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。
- 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。

**检测死锁：**

```mysql
数据库系统实现了各种死锁检测和死锁超时的机制，InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。
```

**死锁恢复：**

```mysql
死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁；
InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。
所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。
```

**外部锁的死锁检测：**

```mysql
发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续
完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通
过设置锁等待超时参数 innodb_lock_wait_timeout 来解决。
```

**死锁影响性能：**

```mysql
死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。
在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，
禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。
```

### MyISAM避免死锁

```mysql
在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。
```

### InnoDB避免死锁

```mysql
1、为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的
每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。

2、在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时
再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁

3、如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果
不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。

4、通过SELECT ... LOCK IN SHARE MODE获取行的读锁后，如果当前事务再需要对该记录进行更新操作，
则很有可能造成死锁。

如果出现死锁，可以用 SHOW INNODB STATUS 命令来确定最后一个死锁产生的原因。返回结果中包括
死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回
滚的事务等。据此可以分析死锁产生的原因和改进措施。
```

### 一些优化锁性能的建议

- 尽量使用较低的隔离级别；
- 精心设计索引， 并尽量使用索引访问数据， 使加锁更精确， 从而减少锁冲突的机会
- 选择合理的事务大小，小事务发生锁冲突的几率也更小
- 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁
- 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会
- 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
- 不要申请超过实际需要的锁级别
- 除非必须，查询时不要显示加锁。 MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能；MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作
- 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能

### 什么叫悲观锁？什么叫乐观锁？

**乐观锁(Optimistic Lock)：**

```mysql
假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。

乐观锁, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在
更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于
多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。
```

**悲观锁(Pessimistic Lock)：**

```mysql
假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。

悲观锁，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候
都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多
这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。
```

### 锁的类型用过哪些

### 乐观锁如何保证最终一致性？

## 主从

[6 种 MySQL 数据库平滑扩容方案剖析](https://mp.weixin.qq.com/s/k-WnKce2o92h1-RRvQolJw)

### mysql主从同步过程了解吗？

### 复制原理及流程

## 缓存

### 缓存和数据库一致性的问题

[如何保持mysql和redis中数据的一致性？](https://www.zhihu.com/question/319817091/answer/2176813916)

## 知道mysqlinnodb是什么数据结构吗？

## 数据库加密算法是怎么设计的？设计这种东西通用规范是怎么设计的？

## 日志

[mysql日志](https://www.cnblogs.com/MrYuChen-Blog/p/15692854.html)

[mysql常用命令&架构&引擎](https://www.cnblogs.com/MrYuChen-Blog/p/15649937.html)
